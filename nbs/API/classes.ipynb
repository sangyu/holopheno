{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classes\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| export\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import scipy \n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "import io\n",
    "import sklearn\n",
    "import os\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "import holopheno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class HoloPheno(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Class for visualizing behavior data in reduced dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, x = None, y = None):\n",
    "        \"\"\"\n",
    "\n",
    "        Reads and stores information from \n",
    "\n",
    "        Parameters\n",
    "\n",
    "        -------\n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        from holopheno.plot_tools import scale_with_columns\n",
    "        self.data_in = data.dropna().reset_index(drop = True).copy()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.summarize() \n",
    "        self.scaled_data = pd.concat([self.data_in[x], scale_with_columns(self.data_in[y])], axis = 1)\n",
    "        \n",
    "    def summarize(self):\n",
    "\n",
    "        self.summary = {}\n",
    "        self.summary['sample_size'] = len(self.data_in)\n",
    "        if self.x:\n",
    "            for x in self.x:\n",
    "                self.summary['unique ' + x + ' values'] = self.data_in[x].unique()\n",
    "        print('Data info: \\n')\n",
    "        for i, (k, v) in enumerate(self.summary.items()):\n",
    "            print(k,  v)\n",
    "        \n",
    "    def scatter(self, x, y, group_by, type = 'raw'):\n",
    "        from holopheno.plot_tools import scatter_with_ellipse\n",
    "        if type == 'raw':\n",
    "            data = self.data_in\n",
    "        elif type == 'scaled':\n",
    "            data = self.scaled_data\n",
    "        f =  scatter_with_ellipse(data, x, y, group_by)\n",
    "        \n",
    "    def scatter_3d(self, metrics, color_by, palette = None, type = 'raw'):\n",
    "        from holopheno.plot_tools import plot_3d_scatter\n",
    "        if type == 'raw':\n",
    "            data = self.data_in\n",
    "        elif type == 'scaled':\n",
    "            data = self.scaled_data\n",
    "        f_3d = plot_3d_scatter(data, metrics, color_by, palette)\n",
    "        return f_3d\n",
    "\n",
    "    def dim_red_by_pca(self, n_components = None, plot_variance_explained = True):\n",
    "        data = self.scaled_data[self.y]\n",
    "        def fit_pca(data = data, n_components =  n_components):\n",
    "            from sklearn.decomposition import PCA\n",
    "            if n_components is None:\n",
    "                n_components = len(self.y)\n",
    "            pca = PCA(n_components = n_components)\n",
    "            pca.fit(data)\n",
    "            return pca\n",
    "        def plot_pca_exp_var(pca):\n",
    "            import matplotlib.pyplot as plt\n",
    "            f = plt.figure\n",
    "            plt.plot(range(1, pca.n_components+1), pca.explained_variance_ratio_.cumsum(), marker = 'o', linestyle = '-')\n",
    "            plt.title('Explained Variance by Components')\n",
    "            plt.xlabel('Number of Components')\n",
    "            plt.ylabel('Cumulative Explained Variance')\n",
    "            return f\n",
    "        pca = fit_pca(data = data, n_components = n_components)\n",
    "        if plot_variance_explained == True:\n",
    "            f = plot_pca_exp_var(pca)\n",
    "            return pca, f\n",
    "        else:\n",
    "            return pca\n",
    "    \n",
    "    def heatmap_zscore(self, group_by, fig_size = None, ax = None, heatmap_kwargs = {'cmap': 'vlag'}, type = 'scaled' ):\n",
    "        from holopheno.plot_tools import plot_heatmap\n",
    "\n",
    "        if type == 'raw':\n",
    "            data = self.data_in\n",
    "        elif type == 'scaled':\n",
    "            data = self.scaled_data\n",
    "        if ax == None:\n",
    "            plot_heatmap(data, group_by, fig_size = fig_size, ax = ax)\n",
    "        else:\n",
    "            self.zscore_heatmap = plot_heatmap(data, group_by, fig_size = fig_size, ax = ax)\n",
    "\n",
    "    \n",
    "    # def corr_matrix_heatmap():\n",
    "        \n",
    "\n",
    "    def transform_with_pca(self, pca):  \n",
    "        import pandas as pd\n",
    "        data = self.scaled_data[self.y]\n",
    "        scores = pca.transform(data)\n",
    "        PCs = pd.DataFrame()\n",
    "        for i in range(scores.shape[1]):   \n",
    "            PCs.insert(i, 'PC'+str(i+1), scores[:, i])\n",
    "        self.scaled_data = pd.concat([self.scaled_data.drop(columns = list(self.scaled_data.filter(regex='PC'))), PCs], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
